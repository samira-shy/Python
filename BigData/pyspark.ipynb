{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73533c2d-00de-424e-92e7-52c33ba89df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.4\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Test\").getOrCreate()\n",
    "\n",
    "print(spark.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68643e99-e56e-4b0f-9d75-6ec118dc2efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "960bbfbb-4441-49ac-bf94-b22dae250ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/17 19:33:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef6d712f-81bc-4941-90ae-b6d14af43ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing example.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile example.txt\n",
    "first line\n",
    "second line\n",
    "third line\n",
    "forth line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "263c9259-d7d4-4e00-adfc-53f12d53f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RDD using a textFile method\n",
    "textFile=sc.textFile('example.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595814f2-4fec-47cf-bb6c-87768703b3b5",
   "metadata": {},
   "source": [
    "## PySpark RDD Transformations & Actions\n",
    "\n",
    "* Transformations create a new RDD from an existing one.\n",
    "* Actions trigger execution and return results to the driver.\n",
    "* RDDs are immutable, meaning transformations create a new RDD.\n",
    "---\n",
    "\n",
    "# RDD Transformations\n",
    "\n",
    "| **Transformation**    | **Description** |\n",
    "|----------------------|----------------|\n",
    "| `map(func)`         | Applies `func` to each element and returns a new RDD |\n",
    "| `flatMap(func)`     | Similar to `map()`, but flattens nested lists |\n",
    "| `filter(func)`      | Filters elements based on `func` |\n",
    "| `groupByKey()`      | Groups data by key (used for key-value pairs) |\n",
    "| `reduceByKey(func)` | Applies `func` to reduce values for each key |\n",
    "| `sortByKey()`       | Sorts the RDD by key |\n",
    "| `join(rdd2)`        | Joins two RDDs based on keys |\n",
    "| `coalesce(n)`       | Reduces the number of partitions |\n",
    "| `distinct()`        | Removes duplicate values |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab13332b-d963-4149-a132-f87702e0731b",
   "metadata": {},
   "source": [
    "## RDD Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbd8170f-462a-4408-b61a-ba5b7b8de327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "788cf6a5-1880-4d59-be71-5723f3232e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first line'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7784f976-33d3-4fcf-b4e0-1999f39ecb24",
   "metadata": {},
   "source": [
    "## RDD Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c41a48-6e83-4ede-bb50-9c45d682e03c",
   "metadata": {},
   "source": [
    "### `filter()`: Filter specific values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdbe7d5f-d23c-41d2-919a-2075d7b4711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1 transformation\n",
    "secfind=textFile.filter(lambda line:'line' in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39115385-a27e-4c47-91dd-9d1e3887aea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first line', 'second line', 'third line', 'forth line']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 2 action\n",
    "secfind.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cbf4dfa0-2642-4487-95e9-625d0d8dff65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered RDD: [('129', 450.0), ('131', 300.0)]\n"
     ]
    }
   ],
   "source": [
    "# Filter transactions greater than 200\n",
    "filtered_rdd = kv_rdd.filter(lambda x: x[1] > 200)\n",
    "print(\"Filtered RDD:\", filtered_rdd.collect())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffe0e3f-1553-49ed-b430-29938a73e284",
   "metadata": {},
   "source": [
    "### `groupByKey()`: Group data by key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7440a6a6-6310-4f08-b0a0-ae8a5ebbdd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped RDD: [('121', [200.0]), ('122', [150.0]), ('131', [100.0, 300.0]), ('129', [450.0])]\n"
     ]
    }
   ],
   "source": [
    "# Group transactions by ServiceID\n",
    "grouped_rdd = kv_rdd.groupByKey().mapValues(list)\n",
    "print(\"Grouped RDD:\", grouped_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "660b36e3-f4ed-43d4-8930-034fe9500b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secfind.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6a21b4d-975e-46b3-8362-28dfd6ab9f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing example2.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile example2.txt\n",
    "first \n",
    "second line\n",
    "the third line\n",
    "then a fourth line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b83101ed-820b-418a-8f57-0d1497c3614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3349572f-2f5d-4f3a-8c26-a1757cdd3bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/14 12:50:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c988bfe-df14-4dbf-bbae-f423707c84e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "example2.txt MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show RDD\n",
    "sc.textFile('example2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaa27eb5-4693-49af-8af9-bb686c3ea502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a reference to this RDD\n",
    "text_rdd = sc.textFile('example2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efa46a6b-73f3-4c52-afa4-60c19276d7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['first'],\n",
       " ['second', 'line'],\n",
       " ['the', 'third', 'line'],\n",
       " ['then', 'a', 'fourth', 'line']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map a function (or lambda expression) to each line\n",
    "# Then collect the results.\n",
    "text_rdd.map(lambda line: line.split()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19edfea6-2bbe-4b66-86fc-99e09add3ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = text_rdd.map(lambda line: line.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6748bc76-fc58-4363-9041-36cc3e66802f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['first'],\n",
       " ['second', 'line'],\n",
       " ['third', 'line'],\n",
       " ['the', 'a', 'forth', 'line']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output: Splits every line into a list of the words\n",
    "word.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f9b84bc-d54a-4e31-9253-d4e62efd2868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first', 'second line', 'third line', 'the a forth line']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output: each string in the list\n",
    "text_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7244667e-2b9d-47ff-9eb2-c9da7ef6fc81",
   "metadata": {},
   "source": [
    "## Explore Map() vs FlatMap(): \n",
    "\n",
    "`flatMap()`: Flatten nested structures (Flatten nested structures). collects everything as a single flatMap Transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "812416de-1742-44f3-8b43-9f3053810b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first', 'second', 'line', 'third', 'line', 'the', 'a', 'forth', 'line']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we did Transformation step, and action step in one line\n",
    "text_rdd.flatMap(lambda line:line.split()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fbc157e6-cf82-4eb4-adee-7444ecf09adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlatMapped RDD: ['201', '10/13/2017', '100', 'NY', '131', '100.00', '204', '10/18/2017', '700', 'TX']\n"
     ]
    }
   ],
   "source": [
    "# Split rows into words\n",
    "words_rdd = rdd.flatMap(lambda line: line.split())\n",
    "print(\"FlatMapped RDD:\", words_rdd.take(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f0b1ff-233b-4077-bb30-8b4bf6d5e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split rows into words\n",
    "words_rdd = rdd.flatMap(lambda line: line.split())\n",
    "print(\"FlatMapped RDD:\", words_rdd.take(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e94937d-6d30-4b64-b900-fff79d221bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first',\n",
       " 'second',\n",
       " 'line',\n",
       " 'the',\n",
       " 'third',\n",
       " 'line',\n",
       " 'then',\n",
       " 'a',\n",
       " 'fourth',\n",
       " 'line']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect everything as a single flat map\n",
    "text_rdd.flatMap(lambda line: line.split()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5c2ef2-9a53-4170-b45a-a9b8d7e4767b",
   "metadata": {},
   "source": [
    "## RDDs and Key Value Pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaa513ed-9f48-4219-9ed5-c0cba1708aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting services.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile services.txt\n",
    "#EventId    Timestamp    Customer   State    ServiceID    Amount\n",
    "201       10/13/2017      100       NY       131          100.00\n",
    "204       10/18/2017      700       TX       129          450.00\n",
    "202       10/15/2017      203       CA       121          200.00\n",
    "206       10/19/2017      202       CA       131          500.00\n",
    "203       10/17/2017      101       NY       173          750.00\n",
    "205       10/19/2017      202       TX       121          200.00\n",
    "206       10/19/2017      200       TX       131          300.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3345472a-a3a3-4ac8-b9af-0ff3d62d73af",
   "metadata": {},
   "outputs": [],
   "source": [
    "services = sc.textFile('services.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1e5cafb-33b1-4faa-a6e4-e0d259adcc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['#EventId    Timestamp    Customer   State    ServiceID    Amount',\n",
       " '201       10/13/2017      100       NY       131          100.00']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 2 elements of RDD\n",
    "services.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654acc51-5c56-48e9-b33c-25f883de33eb",
   "metadata": {},
   "source": [
    "`map()`: Apply function to each row. To split up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90a0681f-e8f2-4da8-81c5-f850dc5b39a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[3] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services.map(lambda line: line.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c45deffb-0687-47e6-abc9-073549094635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['#EventId', 'Timestamp', 'Customer', 'State', 'ServiceID', 'Amount'],\n",
       " ['201', '10/13/2017', '100', 'NY', '131', '100.00'],\n",
       " ['204', '10/18/2017', '700', 'TX', '129', '450.00']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services.map(lambda x: x.split()).take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87cece27-6f18-4270-ab02-bf744f0dad04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['#EventId', 'Timestamp', 'Customer', 'State', 'ServiceID', 'Amount'],\n",
       " ['201', '10/13/2017', '100', 'NY', '131', '100.00'],\n",
       " ['204', '10/18/2017', '700', 'TX', '129', '450.00'],\n",
       " ['202', '10/15/2017', '203', 'CA', '121', '200.00'],\n",
       " ['206', '10/19/2017', '202', 'CA', '131', '500.00'],\n",
       " ['203', '10/17/2017', '101', 'NY', '173', '750.00'],\n",
       " ['205', '10/19/2017', '202', 'TX', '121', '200.00']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services.map(lambda line: line.split()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2dcb2e-fa9d-45f9-96b6-7edc2c70c4f3",
   "metadata": {},
   "source": [
    "### Remove the hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6de30e56-58a9-429e-b93e-949a7306bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtag_remove(line):\n",
    "    if line[0]=='#':\n",
    "        return line[1:]\n",
    "    else: return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d15131de-91e9-46f3-8bcf-6e2c6545a8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EventId    Timestamp    Customer   State    ServiceID    Amount',\n",
       " '201       10/13/2017      100       NY       131          100.00',\n",
       " '204       10/18/2017      700       TX       129          450.00',\n",
       " '202       10/15/2017      203       CA       121          200.00',\n",
       " '206       10/19/2017      202       CA       131          500.00',\n",
       " '203       10/17/2017      101       NY       173          750.00',\n",
       " '205       10/19/2017      202       TX       121          200.00']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services.map(hashtag_remove).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9536d139-22ec-4049-a3f7-1503346ad190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda expression for removing hashtag\n",
    "# lambda arguments: result_if_true if condition else result_if_false\n",
    "process_line = lambda line: line[1:] if line[0]=='#' else line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f81ec2fd-8e7d-475f-ac9a-8e9bfe2c5e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dsdss'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_line('#dsdss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3120b82a-735c-461b-89e7-fa0559ce962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_rdd = services.map(process_line).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24424003-7c0d-4722-8a97-21a843c6fd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EventId    Timestamp    Customer   State    ServiceID    Amount', '201       10/13/2017      100       NY       131          100.00', '204       10/18/2017      700       TX       129          450.00', '202       10/15/2017      203       CA       121          200.00', '206       10/19/2017      202       CA       131          500.00', '203       10/17/2017      101       NY       173          750.00', '205       10/19/2017      202       TX       121          200.00']\n"
     ]
    }
   ],
   "source": [
    "print(processed_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a42fcf2-c3b5-4513-9048-4f60dbf22b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EventId    Timestamp    Customer   State    ServiceID    Amount',\n",
       " '201       10/13/2017      100       NY       131          100.00',\n",
       " '204       10/18/2017      700       TX       129          450.00',\n",
       " '202       10/15/2017      203       CA       121          200.00',\n",
       " '206       10/19/2017      202       CA       131          500.00',\n",
       " '203       10/17/2017      101       NY       173          750.00',\n",
       " '205       10/19/2017      202       TX       121          200.00',\n",
       " '206       10/19/2017      200       TX       131          300.00']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing hash tag. Grab everything from index 1\n",
    "services.map(lambda line: line[1:] if line[0]=='#' else line).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e43d2c-1044-46f7-8046-d0366def6882",
   "metadata": {},
   "source": [
    "### Now that we cleaned and removed `#` we grab the first three onj of RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7c75b00-c3ef-4189-a807-5f9328312cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = services.map(lambda line: line[1:] if line[0]=='#' else line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75b00bf8-0070-472b-ae2d-e16d20b00c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = clean.map(lambda line: line.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0be73d36-683f-420d-81d8-94454b3d3594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['EventId', 'Timestamp', 'Customer', 'State', 'ServiceID', 'Amount'],\n",
       " ['201', '10/13/2017', '100', 'NY', '131', '100.00'],\n",
       " ['204', '10/18/2017', '700', 'TX', '129', '450.00'],\n",
       " ['202', '10/15/2017', '203', 'CA', '121', '200.00'],\n",
       " ['206', '10/19/2017', '202', 'CA', '131', '500.00'],\n",
       " ['203', '10/17/2017', '101', 'NY', '173', '750.00'],\n",
       " ['205', '10/19/2017', '202', 'TX', '121', '200.00'],\n",
       " ['206', '10/19/2017', '200', 'TX', '131', '300.00']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bc5e69-2dba-41a0-9481-e3bfdf26c92f",
   "metadata": {},
   "source": [
    "### Grab fields:\n",
    "Get the total sells per state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96e1601d-cdde-4971-8902-8f1016157bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. collect the state and amount columns\n",
    "pairs = clean.map(lambda lst:(lst[3],lst[-1])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "163d987f-8ea2-49c2-a434-38267f92f753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('State', 'Amount'), ('NY', '100.00'), ('TX', '450.00'), ('CA', '200.00'), ('CA', '500.00'), ('NY', '750.00'), ('TX', '200.00'), ('TX', '300.00')]\n"
     ]
    }
   ],
   "source": [
    "print(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cba7776-7ae8-46f7-bace-05935aea83ad",
   "metadata": {},
   "source": [
    "## ReduceByKey() in PySpark\n",
    "\n",
    "### What is `reduceByKey()`?\n",
    "`reduceByKey()` is a transformation in PySpark used for **aggregating values** by key in an RDD. It groups the data by key and applies a reduction function to combine the values.\n",
    "\n",
    "#### **Syntax**\n",
    "```python\n",
    "rdd.reduceByKey(lambda a, b: a + b)\n",
    "```\n",
    "- **`a` and `b`** are values associated with the same key.\n",
    "- The function (`a + b`) is applied iteratively to combine the values.\n",
    "\n",
    "---\n",
    "\n",
    "### **Apply `reduceByKey()`**\n",
    "```python\n",
    "# Sum sales amount for each state\n",
    "result_rdd = rdd.reduceByKey(lambda amt1, amt2: float(amt1) + float(amt2))\n",
    "\n",
    "# Collect and display the output\n",
    "result = result_rdd.collect()\n",
    "print(result)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Expected Output**\n",
    "```python\n",
    "[(\"NY\", 850), (\"TX\", 950), (\"CA\", 700)]\n",
    "```\n",
    "Here’s how the function works internally:\n",
    "- NY: `100 + 750 = 850`\n",
    "- TX: `450 + 200 + 300 = 950`\n",
    "- CA: `200 + 500 = 700`\n",
    "\n",
    "---\n",
    "\n",
    "### ** Explanation of `reduceByKey()` in Detail**\n",
    "1. **Grouping by Key**\n",
    "   `reduceByKey()` groups values that share the same key.\n",
    "    Grouping by Key (groupBy concept inside reduceByKey), Spark automatically groups elements with the same key:\n",
    "\n",
    "- 'NY': [100.00, 750.00]\n",
    "- 'TX': [450.00, 200.00, 300.00]\n",
    "- 'CA': [200.00, 500.00]\n",
    "  \n",
    "This step is internally done by reduceByKey() (similar to groupByKey(), but more efficient because it combines values during shuffling).\n",
    "\n",
    "---\n",
    "2. **Applying the Function**\n",
    "\n",
    "\n",
    "    - Pairwise Reduction (How Lambda Works) Now, reduceByKey() applies lambda :\n",
    "      lambda amt1, amt2: float(amt1) + float(amt2) pairwise on the values until only one value remains per key:\n",
    "  \n",
    "      \n",
    "    NY:\n",
    "    100.00 + 750.00 = 850.00\n",
    "\n",
    "   \n",
    "    It takes 100.00 and 750.00, applies the function (amt1 + amt2), and keeps 850.00.\n",
    "\n",
    "   \n",
    "    TX:\n",
    "    450.00 + 200.00 = 650.00\n",
    "    650.00 + 300.00 = 950.00\n",
    "\n",
    "   \n",
    "    First, it adds 450.00 and 200.00 → gets 650.00. Then, it takes 650.00 and 300.00 → gets 950.00.\n",
    "\n",
    "   \n",
    "    CA:\n",
    "    200.00 + 500.00 = 700.00\n",
    "    Just one pairwise addition needed.\n",
    "\n",
    "   - It starts with the first two values and applies `lambda amt1, amt2: amt1 + amt2`.\n",
    "   - The result is used in the next step until all values are aggregated.\n",
    "     \n",
    "4. **Efficient Execution**\n",
    "   - `reduceByKey()` is more efficient than `groupByKey()` since it reduces data **before shuffling** across nodes.\n",
    "\n",
    "---\n",
    "\n",
    "### **Alternative Functions**\n",
    "#### **Find Maximum Sales for Each State**\n",
    "```python\n",
    "max_sales_rdd = rdd.reduceByKey(lambda a, b: max(a, a))\n",
    "print(max_sales_rdd.collect())\n",
    "```\n",
    "#### **Find Minimum Sales for Each State**\n",
    "```python\n",
    "min_sales_rdd = rdd.reduceByKey(lambda a, b: min(a, b))\n",
    "print(min_sales_rdd.collect())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "- `reduceByKey()` helps in aggregating key-value RDDs efficiently.\n",
    "- It reduces data early to optimize performance.\n",
    "- Use cases include **sum, count, max, min, and other aggregations** by key.\n",
    "- reduceByKey() partially reduces values before shuffling. This means it:\n",
    "  \n",
    "      ✅ Uses less memory\n",
    "      ✅ Reduces network traffic\n",
    "      ✅ Is faster for large datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e719d85-8131-41e2-905a-cbbca197164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = clean.map(lambda lst:(lst[3],lst[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b111e7fc-2682-4021-945f-e30e31a125dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Reduce by key\n",
    "# When using lambda amt1, amt2: float(amt1) + float(amt2), \n",
    "# the two variables (amt1 and amt2) \n",
    "# represent two amounts that belong to the same key (state in this case).\n",
    "rekey=pairs.reduceByKey(lambda amt1,amt2:amt1+amt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "595919b2-1445-4f8f-b750-d1319d485afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('State', 'Amount'),\n",
       " ('NY', '100.00750.00'),\n",
       " ('TX', '450.00200.00300.00'),\n",
       " ('CA', '200.00500.00')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rekey.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0405abb2-aef9-4f19-85fd-1b433b9606d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rekey = pairs.reduceByKey(lambda amt1,amt2: float(amt1)+float(amt2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0996f99-3e69-4b4c-8b16-6afea029fbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('State', 'Amount'), ('NY', 850.0), ('TX', 950.0), ('CA', 700.0)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rekey.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "191a56b2-641d-4647-a14a-7a42e51c3634",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (3331101979.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[29], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    step3 = rekey.filter(lambda x:not x[0]== 'state)\u001b[0m\n\u001b[0m                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "# 3. get rid of state, amount title\n",
    "step3 = rekey.filter(lambda x:not x[0]== 'state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a31d88b-16d0-4db2-ba54-be5c45b37eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 4. sort by amount\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6610fc-06e6-4bac-bef6-d5c48d92ce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "step1 = clean.map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0ca3251a-547a-49e2-9e7c-365cfb7b8c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As previously it only concatinate string we convert it to float\n",
    "rekey=pairs.reduceByKey(lambda amt1,amt2:float(amt1)+float(amt2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "37805cc7-f789-4cae-82bc-cede49fbb41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('State', 'Amount'), ('NY', 850.0), ('TX', 650.0), ('CA', 700.0)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rekey.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f00d1ae4-7e63-4264-b01f-5eb59be743c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped RDD: [('131', 100.0), ('129', 450.0), ('121', 200.0), ('131', 300.0), ('122', 150.0)]\n"
     ]
    }
   ],
   "source": [
    "# Extract ServiceID and Amount as key-value pairs\n",
    "kv_rdd = rdd.map(lambda line: (line.split()[4], float(line.split()[-1])))\n",
    "print(\"Mapped RDD:\", kv_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b1a49226-9d2a-4f3d-88ca-d21dc182ed13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile data2.txt\n",
    "#ID    Name    Age    City    Score\n",
    "1      John    25     NY      85.5\n",
    "2      Jane    30     TX      92.0\n",
    "3      Alice   27     CA      88.0\n",
    "4      Bob     24     FL      79.5\n",
    "5      Eve     29     WA      95.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "667ed3d4-eae6-4ecb-b9e6-704bd52bdc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['EventId', 'Timestamp', 'Customer', 'State', 'ServiceID', 'Amount'],\n",
       " ['201', '10/13/2017', '100', 'NY', '131', '100.00'],\n",
       " ['204', '10/18/2017', '700', 'TX', '129', '450.00'],\n",
       " ['202', '10/15/2017', '203', 'CA', '121', '200.00'],\n",
       " ['206', '10/19/2017', '202', 'CA', '131', '500.00'],\n",
       " ['203', '10/17/2017', '101', 'NY', '173', '750.00'],\n",
       " ['205', '10/19/2017', '202', 'TX', '121', '200.00']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services.map(lambda x: x[1:] if x[0]=='#' else x).map(lambda x: x.split()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e78daa-d795-4445-a310-c555076f261a",
   "metadata": {},
   "source": [
    "Here's your **Jupyter Notebook Markdown tutorial** for **RDD Actions** in PySpark. It includes a **pretext table** explaining each action and the corresponding **Python code** in proper markdown formatting.\n",
    "\n",
    "---\n",
    "\n",
    "### **RDD Actions in PySpark**  \n",
    "\n",
    "#### **Action Description Table**\n",
    "| Action             | Description |\n",
    "|--------------------|------------|\n",
    "| `count()`         | Counts total rows |\n",
    "| `first()`         | Retrieves first row |\n",
    "| `collect()`       | Converts RDD to list |\n",
    "| `take(n)`        | Fetches first `n` rows |\n",
    "| `distinct()`      | Returns distinct rows |\n",
    "| `reduce()`        | Applies a function to aggregate values |\n",
    "| `max()`           | Finds the maximum value |\n",
    "| `min()`           | Finds the minimum value |\n",
    "| `countByKey()`    | Counts occurrences of each key |\n",
    "| `keys()`          | Retrieves all keys in an RDD |\n",
    "| `values()`        | Retrieves all values in an RDD |\n",
    "| `isEmpty()`       | Checks if RDD is empty |\n",
    "| `takeSample(False, n)` | Takes `n` random samples |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a64cbd82-b98b-46f3-a6f0-181a839b37c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile data.txt\n",
    "#EventId    Timestamp    Customer   State    ServiceID    Amount\n",
    "201       10/13/2017      100       NY       131          100.00\n",
    "204       10/18/2017      700       TX       129          450.00\n",
    "202       10/15/2017      203       CA       121          200.00\n",
    "205       10/20/2017      404       FL       131          300.00\n",
    "203       10/17/2017      305       TX       122          150.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dda6ebe0-5057-4af1-b1af-df56b03fe4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/apple/Documents/GitHub/Python/BigData\n",
      "['services.txt', '.DS_Store', 'example2.txt', 'lambda_expressions.ipynb', 'example.txt', '.ipynb_checkpoints', 'pyspark.ipynb', 'data.txt']\n"
     ]
    }
   ],
   "source": [
    "# To check the saved file, run:\n",
    "import os\n",
    "print(os.getcwd())  # Shows current working directory\n",
    "print(os.listdir())  # Lists files in the directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dfb2c393-1897-401d-9f0d-fb64e7995b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['201       10/13/2017      100       NY       131          100.00',\n",
       " '204       10/18/2017      700       TX       129          450.00',\n",
       " '202       10/15/2017      203       CA       121          200.00']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data.txt into an RDD (excluding header)\n",
    "rdd = sc.textFile(\"data.txt\").filter(lambda line: not line.startswith(\"#\"))\n",
    "\n",
    "# Display first few lines\n",
    "rdd.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a5f35a-137d-47da-8a30-7b64a6362eb3",
   "metadata": {},
   "source": [
    "## RDD Actions in PySpark\n",
    "- Actions are operations that **trigger computation and return values to the driver**.\n",
    "### **Basic Actions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "969f7ca0-4d64-49f8-b981-9df8f77ce64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 5\n"
     ]
    }
   ],
   "source": [
    "# Count number of records\n",
    "print(\"Total rows:\", rdd.count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "81a7a35e-a4d3-42af-acef-dd2fc9dc43ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: 201       10/13/2017      100       NY       131          100.00\n"
     ]
    }
   ],
   "source": [
    "# Show the first row\n",
    "print(\"First row:\", rdd.first())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5e32efa7-9f26-49ec-b83f-f3370d19907e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All records: ['201       10/13/2017      100       NY       131          100.00', '204       10/18/2017      700       TX       129          450.00', '202       10/15/2017      203       CA       121          200.00', '205       10/20/2017      404       FL       131          300.00', '203       10/17/2017      305       TX       122          150.00']\n"
     ]
    }
   ],
   "source": [
    "# Collect all records into a list\n",
    "print(\"All records:\", rdd.collect())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a1a4323e-7126-446b-baf7-211e9bdca51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 rows: ['201       10/13/2017      100       NY       131          100.00', '204       10/18/2017      700       TX       129          450.00', '202       10/15/2017      203       CA       121          200.00']\n"
     ]
    }
   ],
   "source": [
    "# Take the first 3 rows\n",
    "print(\"First 3 rows:\", rdd.take(3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b866cf94-d23b-4b9b-b653-4a58f48011be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct rows: ['204       10/18/2017      700       TX       129          450.00', '202       10/15/2017      203       CA       121          200.00', '205       10/20/2017      404       FL       131          300.00', '203       10/17/2017      305       TX       122          150.00', '201       10/13/2017      100       NY       131          100.00']\n"
     ]
    }
   ],
   "source": [
    "# Retrieve distinct rows\n",
    "print(\"Distinct rows:\", rdd.distinct().collect())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c690dd44-8a11-45e8-8f95-e694075cc147",
   "metadata": {},
   "source": [
    "### **Numeric Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e1c0a909-b16d-4941-9d0e-2635821e7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract the \"Amount\" column (last column) and convert to float\n",
    "amount_rdd = rdd.map(lambda line: float(line.split()[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1cc6d770-9b22-434e-8c84-bfc2586acc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Amount: 1200.0\n"
     ]
    }
   ],
   "source": [
    "# Find the total sum of Amount\n",
    "total_amount = amount_rdd.reduce(lambda x, y: x + y)\n",
    "print(\"Total Amount:\", total_amount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "10cb8d93-23a9-4329-87da-3f61fb5fb975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Amount: 450.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Find the maximum transaction amount\n",
    "max_amount = amount_rdd.max()\n",
    "print(\"Max Amount:\", max_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6214b66c-d897-428f-968e-2d34f2db1efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Amount: 100.0\n"
     ]
    }
   ],
   "source": [
    "# Find the minimum transaction amount\n",
    "min_amount = amount_rdd.min()\n",
    "print(\"Min Amount:\", min_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9d1be10e-4be8-4356-9b27-0d18f8f65adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Amount: 240.0\n"
     ]
    }
   ],
   "source": [
    "# Compute average amount\n",
    "avg_amount = total_amount / amount_rdd.count()\n",
    "print(\"Average Amount:\", avg_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d332b04e-6136-4a33-8c06-cda366ee8e3c",
   "metadata": {},
   "source": [
    "### **Some other Useful Actions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ba334239-00b5-4719-acc4-9935307f9e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key-Value pairs: [('131', 100.0), ('129', 450.0)]\n"
     ]
    }
   ],
   "source": [
    "# Get the first 2 records as key-value pairs (ServiceID, Amount)\n",
    "kv_rdd = rdd.map(lambda line: (line.split()[4], float(line.split()[-1])))\n",
    "print(\"Key-Value pairs:\", kv_rdd.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e59e8173-1119-4f2b-81e8-266bdb61e7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count per ServiceID: {'131': 2, '129': 1, '121': 1, '122': 1}\n"
     ]
    }
   ],
   "source": [
    "# Count by key (ServiceID)\n",
    "service_count = kv_rdd.countByKey()\n",
    "print(\"Count per ServiceID:\", dict(service_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "16c34c27-004e-4a13-85c9-c254f80b3710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All ServiceIDs: ['131', '129', '121', '131', '122']\n"
     ]
    }
   ],
   "source": [
    "# Fetch all keys (ServiceIDs)\n",
    "print(\"All ServiceIDs:\", kv_rdd.keys().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5572f0df-ed28-4f48-b127-42e5d45e9808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Amounts: [100.0, 450.0, 200.0, 300.0, 150.0]\n"
     ]
    }
   ],
   "source": [
    "# Fetch all values (Amounts)\n",
    "print(\"All Amounts:\", kv_rdd.values().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0bc80e73-b135-44f2-8aca-01a669325cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is RDD empty? False\n"
     ]
    }
   ],
   "source": [
    "# Check if RDD is empty\n",
    "print(\"Is RDD empty?\", rdd.isEmpty())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b940d267-19ff-432f-997a-a4fc72d35447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Records: ['201       10/13/2017      100       NY       131          100.00', '204       10/18/2017      700       TX       129          450.00']\n"
     ]
    }
   ],
   "source": [
    "# Take a sample (without replacement)\n",
    "print(\"Sample Records:\", rdd.takeSample(False, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d5070d-9b06-4692-b199-80e69880783f",
   "metadata": {},
   "source": [
    "**Try using tuple unpacking for readability.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "313945c0-d4e1-4a7a-aa0c-3ff0996e77af",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['ID','State','Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5e3da0a9-1995-4318-9ae1-deae1baf4ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1(lst):\n",
    "    return lst[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a4ea7826-9eba-4f7b-bef8-e88593e1ea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func2(id_st_amt):\n",
    "    # tuple unpacking\n",
    "    (ids,st,amt)=id_st_amt\n",
    "    return amt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6276235d-09e0-455c-bfc3-13cb46a4862f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amount'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "78de2ff8-562b-4912-8a5d-c3810cb38ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amount'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1763a8f4-e2a8-4bed-bc5e-0409489333c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PySpark)",
   "language": "python",
   "name": "pyspark_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
