{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73533c2d-00de-424e-92e7-52c33ba89df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.4\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Test\").getOrCreate()\n",
    "\n",
    "print(spark.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68643e99-e56e-4b0f-9d75-6ec118dc2efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "960bbfbb-4441-49ac-bf94-b22dae250ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/06 21:41:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 50039)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pyspark_env/lib/python3.9/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/anaconda3/envs/pyspark_env/lib/python3.9/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/anaconda3/envs/pyspark_env/lib/python3.9/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/anaconda3/envs/pyspark_env/lib/python3.9/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/opt/anaconda3/envs/pyspark_env/lib/python3.9/site-packages/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/opt/anaconda3/envs/pyspark_env/lib/python3.9/site-packages/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "  File \"/opt/anaconda3/envs/pyspark_env/lib/python3.9/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/opt/anaconda3/envs/pyspark_env/lib/python3.9/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef6d712f-81bc-4941-90ae-b6d14af43ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing example.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile example.txt\n",
    "first line\n",
    "second line\n",
    "third line\n",
    "forth line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "263c9259-d7d4-4e00-adfc-53f12d53f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RDD using a textFile method\n",
    "textFile=sc.textFile('example.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab13332b-d963-4149-a132-f87702e0731b",
   "metadata": {},
   "source": [
    "## RDD Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbd8170f-462a-4408-b61a-ba5b7b8de327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "788cf6a5-1880-4d59-be71-5723f3232e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first line'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7784f976-33d3-4fcf-b4e0-1999f39ecb24",
   "metadata": {},
   "source": [
    "## RDD Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdbe7d5f-d23c-41d2-919a-2075d7b4711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1 transformation\n",
    "secfind=textFile.filter(lambda line:'line' in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39115385-a27e-4c47-91dd-9d1e3887aea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first line', 'second line', 'third line', 'forth line']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 2 action\n",
    "secfind.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "660b36e3-f4ed-43d4-8930-034fe9500b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secfind.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6a21b4d-975e-46b3-8362-28dfd6ab9f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing example2.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile example2.txt\n",
    "first \n",
    "second line\n",
    "the third line\n",
    "then a fourth line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b83101ed-820b-418a-8f57-0d1497c3614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3349572f-2f5d-4f3a-8c26-a1757cdd3bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/09 23:35:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c988bfe-df14-4dbf-bbae-f423707c84e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "example2.txt MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show RDD\n",
    "sc.textFile('example2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaa27eb5-4693-49af-8af9-bb686c3ea502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a reference to this RDD\n",
    "text_rdd = sc.textFile('example2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efa46a6b-73f3-4c52-afa4-60c19276d7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['first'],\n",
       " ['second', 'line'],\n",
       " ['the', 'third', 'line'],\n",
       " ['then', 'a', 'fourth', 'line']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map a function (or lambda expression) to each line\n",
    "# Then collect the results.\n",
    "text_rdd.map(lambda line: line.split()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e94937d-6d30-4b64-b900-fff79d221bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first',\n",
       " 'second',\n",
       " 'line',\n",
       " 'the',\n",
       " 'third',\n",
       " 'line',\n",
       " 'then',\n",
       " 'a',\n",
       " 'fourth',\n",
       " 'line']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect everything as a single flat map\n",
    "text_rdd.flatMap(lambda line: line.split()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5c2ef2-9a53-4170-b45a-a9b8d7e4767b",
   "metadata": {},
   "source": [
    "## RDDs and Key Value Pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaa513ed-9f48-4219-9ed5-c0cba1708aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing services.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile services.txt\n",
    "#EventId    Timestamp    Customer   State    ServiceID    Amount\n",
    "201       10/13/2017      100       NY       131          100.00\n",
    "204       10/18/2017      700       TX       129          450.00\n",
    "202       10/15/2017      203       CA       121          200.00\n",
    "206       10/19/2017      202       CA       131          500.00\n",
    "203       10/17/2017      101       NY       173          750.00\n",
    "205       10/19/2017      202       TX       121          200.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3345472a-a3a3-4ac8-b9af-0ff3d62d73af",
   "metadata": {},
   "outputs": [],
   "source": [
    "services = sc.textFile('services.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1e5cafb-33b1-4faa-a6e4-e0d259adcc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#EventId    Timestamp    Customer   State    ServiceID    Amount',\n",
       " '201       10/13/2017      100       NY       131          100.00']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 2 elements of RDD\n",
    "services.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90a0681f-e8f2-4da8-81c5-f850dc5b39a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[11] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services.map(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87cece27-6f18-4270-ab02-bf744f0dad04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['#EventId', 'Timestamp', 'Customer', 'State', 'ServiceID', 'Amount'],\n",
       " ['201', '10/13/2017', '100', 'NY', '131', '100.00'],\n",
       " ['204', '10/18/2017', '700', 'TX', '129', '450.00'],\n",
       " ['202', '10/15/2017', '203', 'CA', '121', '200.00'],\n",
       " ['206', '10/19/2017', '202', 'CA', '131', '500.00'],\n",
       " ['203', '10/17/2017', '101', 'NY', '173', '750.00'],\n",
       " ['205', '10/19/2017', '202', 'TX', '121', '200.00']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services.map(lambda x: x.split()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c45deffb-0687-47e6-abc9-073549094635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['#EventId', 'Timestamp', 'Customer', 'State', 'ServiceID', 'Amount'],\n",
       " ['201', '10/13/2017', '100', 'NY', '131', '100.00'],\n",
       " ['204', '10/18/2017', '700', 'TX', '129', '450.00']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services.map(lambda x: x.split()).take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a42fcf2-c3b5-4513-9048-4f60dbf22b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EventId    Timestamp    Customer   State    ServiceID    Amount',\n",
       " '201       10/13/2017      100       NY       131          100.00',\n",
       " '204       10/18/2017      700       TX       129          450.00',\n",
       " '202       10/15/2017      203       CA       121          200.00',\n",
       " '206       10/19/2017      202       CA       131          500.00',\n",
       " '203       10/17/2017      101       NY       173          750.00',\n",
       " '205       10/19/2017      202       TX       121          200.00']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing hash tag\n",
    "services.map(lambda x: x[1:] if x[0]=='#' else x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667ed3d4-eae6-4ecb-b9e6-704bd52bdc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PySpark)",
   "language": "python",
   "name": "pyspark_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
